# Lets Spark things up!

In this blogpost we will take a first look into spark, specifically we will look into the Resilient Distributed Datasets (RDD) and lazy evaluation used by Spark.

## The RDD
Spark is designed specifically for 'Big Data' projects and uses Resilient Distributed Datasets to do so. The RDD is a dataset home to Spark that partitions its data such that parallelization can be used to up processing speed easily.

